ローカルRAGは4月末までに運用可能か（A4 1〜2枚要約）
==========================================

結論
- 可能。条件（4月まで専念／担当1名／ハイペリオンの高スペック／Windows固定／スピード重視）はRAG案件として有利。
- ただし「完璧な社内AI」を最初から狙うと失敗しやすい。運用に足る最小構成（MVP）→痛い部分だけ段階補強が勝ち筋。

全体方針（3層だけ押さえる）
1) LLMをローカルで安定稼働（GPU/CUDAで速度を出す）
2) 資料を取り込んで検索できるようにする（RAGの検索部分を成立させる）
3) 社内運用の形にする（権限・ログ・更新・事故防止）

最短ロードマップ（一本道）
A. まず「LLMが返事できる」状態（最初の数日）
- Foundry Local または LM Studio 等で gpt-oss 20B を起動し、GPUで安定生成できることを確認
- 生成速度の基準値（例：token/s）を測る
- PythonからAPIで呼べる（サーバ化できる）状態にする
  → ここが通れば、以降は“アプリ側”の問題になる

B. 次に「資料を食わせて答えられる」状態（1〜2週間目標）
- AnythingLLM Desktop 等で、フォルダ取り込み→RAG回答まで一気通す
- 最初は精度70点でもOK（まずは動くこと優先）
- 代表的な質問10〜20個でテストセットを作る（改善の基準点）

C. 最後に「運用に耐える最低限のガード」（残り期間で段階補強）
- 文書更新のルール：夜間再索引、更新フォルダのみ再取り込み、版管理
- 誤回答を減らす工夫：根拠引用必須、不明なら不明と言う、社内規程優先
- ログ：誰が何を聞いたか、どの根拠を参照したか
- 権限制御：まずは部署別フォルダなど“物理分離”で簡易実装（後で高度化）

失敗しやすい点と回避のコツ（重要）
1) PDF問題で時間が溶ける
- スキャンPDF／表が多いPDFは抽出が崩れ、精度が落ちやすい
- 対策：最初はテキスト化済み資料から開始。PDFは「重要なものだけ」個別対策で後回し

2) 「RAG＝ベクトルDB」で沼る
- ベクトルDBは手段。最初から自作せず、RAGアプリの自動索引化で十分なことが多い
- まず“使える形”を作り、必要になったらDBや索引を置き換える

3) 運用要件を後回しにして最後に爆死
- 精度より先に「事故らない仕組み」が重要になることが多い
- 根拠引用、版管理、権限制御、ログは早めに最低限を入れる

知識が少なくても勝てる進め方（現実解）
- 自作を急がない：既製アプリで動かし、必要になったところだけ置き換える
- テスト質問セットを作る：10〜20問でも効果が大きい（改善が迷子にならない）
- 実装より資料整備：版管理・整理の出来が精度と事故率を左右する

目標設定（4月末の現実ライン）
- 「全社の何でも屋AI」ではなく、対象範囲を絞った“業務特化”を目指す
  例：規程QA、手順書QA、問い合わせ一次対応、過去チケット検索
- これなら4月末運用に間に合う確度が高い

（以上）
